#

## 1. 什么样的场景会导致线上CPU负载过高？如何解决

代码层面常见的场景有：

1.线程数量设计不合理
2.大规模的计算
3.程序陷入死循环，不停地消耗CPU
4.线程死锁，线程相互等待，导致假死状态，不停地消耗CPU
5.对于IO密集型任务，protobuf的序列化和反序列化可能会占用30%以上的cpu.
**解决：**

1.使用`top` 命令监控当前系统负载情况。

top -H -p pid: 查看指定进程中每个线程的资源占用情况(每条线程占用CPU时间的百分比)

2.通过一些工具定位到CPU消耗高的函数
**brpc有内置的功能**
3.gcc编译优化，-O2和-O0,cpu消耗差距很大，-O2会低很多

## 2. 频繁的申请和释放内存会出现什么问题?

首先:肯定会产生内存碎片。
其次:内存不断的申请，再不断的释放，程序跑的过程中可能就会出现申请不一定成功，或释放不一定成功，导致出现**内存泄露的现象,频繁申请释放内存导致进程被OOM(out of memory)掉**。

<https://mp.weixin.qq.com/s/pdv5MMUQ9ACpeCpyGnxb1Q>

### 操作系统内存回收机制

## 3. malloc之后再进行free，free的内存空间一定被OS回收了吗？

malloc时，假如申请了1KB的空间，那么操作系统有可能给你一个大于1KB的数值用以备用。同时，malloc时会用一个tag记录本次申请空间的大小，free的时候仅仅将tag清零。
但我有两个问题，比如在基于glibc的Linux中：
1.malloc之后如果不free，那么进程正常(或异常)结束后，操作系统是否一定会对这块内存进行回收呢？
2.malloc之后如果调用了free，那么有没有什么情况下，操作系统不对这块内存进行回收呢？或者说暂时不进行回收呢？

1. 会的，内存也是资源，操作系统会回收的。若不回收，你每次都异常退出去，多来几次，那岂不是你的内存直接就没了。

## 负载均衡的策略有哪些？

1.轮询(Round Robin)
按顺序将请求依次分配给服务器，每个服务器按照顺序依次接收请求。适用于服务器性能相近的情况。

2.最小连接数(Least Connection)
将请求分配给当前连接数最少的服务器，确保负载相对均衡，适用于长连接的场景。

3.最少响应时间(Least Response Time)
将请求分配给响应时间最短的服务器，确保客户端能够获得最快的响应，适用于对响应时间要求较高的场景。

4.IP哈希(IP Hash)
根据请求的源IP地址计算哈希值，将同一IP的请求分配给同一台服务器，保证特定客户端的请求都发送到同一服务器，适用于需要会话保持的应用。

5.加权轮询(Weighted Round Robin)
根据服务器的权重值，按比例分配请求，权重高的服务器接收到的请求数更多。

## 10亿个数据中找出最大的10000个？——最小堆

最小堆法

* 先拿10000个数建堆
* 然后逐个添加剩余元素
* 如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆
* 遍历完后，堆中的10000个数就是所需的最大的10000个。
* 复杂度分析：时间复杂度是O（mlogm），算法的时间复杂度为O（nmlogm）（n为10亿，m为10000）。

优化方法

* 如果内存受限：可以直接在内存总使用Hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑可以采用最小堆，最后一个线程将结果归并。

> 进一步优化：
该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。而针对此问题
解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，直到所有数据处理完毕，最后由一个线程进行归并。

* 如果含较多重复值：先用hash / 依图法去重，可大大节省运算量

## 有几台机器存储着几亿淘宝搜索日志，你只有一台 2g 的电脑，怎么选出搜索热度最高的十个？

针对top k类文本问题，通常比较好的方案是【分治+trie树/hash+小顶堆】，即先将数据集按照hash方法分解成多个小数据集，然后使用trie树或者hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出频率最高的前K个数，最后在所有top K中求出最终的top K。

* 拆分成n多个文件：以首字母区分，不同首字母放在不同文件，长度仍过长的继续按照次首字母进行拆分。这样一来，每个文件的每个数据长度相同且首字母尾字母也相同，就能保证数据被独立的分为了n个文件，且各个文件中不存在关键词的交集。

* 分别词频统计：对于每个文件，使用hash或者Trie树进行进行词频统计

* 小顶堆排序：依次处理每个文件，并逐渐更新最大的十个词

<https://blog.nowcoder.net/n/eb5599d1c1f147a3946df56302b25016>
